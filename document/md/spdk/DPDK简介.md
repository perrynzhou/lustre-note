###  DPDK简介


| 作者 | 时间 |QQ技术交流群 |
| ------ | ------ |------ |
| perrynzhou@gmail.com |2020/12/20 |中国开源存储技术交流群(672152841) |

#### 什么DPDK?

- DPDK是基于IA架构下高速包处理而设计,以软件库形式为上层应用开发提供一个高性能的基础IO开发库，DPDK利用了大量有助于包处理的软硬件特性，如大页、缓存行对齐、线程绑定、预取、NUMA、IA最新指令、Intel DDIO、内存交叉访问等。

#### 为什么需要DPDK?
- 传统的网络设备驱动处理包的流程如下：

  - 数据包到达网卡设备
  - 网卡设备根据配置进行DMA操作
  - 网卡发送中断，唤醒CPU
  - 驱动软件初始化读写缓冲区结构和数据
  - 数据报文达到内核协议栈，进行高层处理
  - 如果应用运行在在用户态，数据从内核迁移到用户态
  - 如果应用运行在内核态，则在内核继续处理

  传统的方式每到一个报文都会触发一个中断,中断带来的开销变得非常突出,大量数据到来回触发频繁的中断开销，导致系统无法承受，因此在后续的Linux内核中引入了NAPI机制,其策略是系统被中断唤醒后，尽量使用轮询的方式一次处理多个数据包，直到网络再次空闲重新转入中断等待。NAPI策略适合于高吞吐量的场景，效率提升明显。

- 二层以太网包经过网络设备驱动处理后，最后大多要给到用户态应用。网络包进入内核都需要经过协议栈(TCP/IP）处理，即使不需要协议处理的场景下，大多数场景数据包也需要从内核的缓冲区复制到用户的缓冲区，系统调用以及数据包的复制开销，会直接影响用户态应用从设备直接获得包的能力，而对于多元化网络功能(核心功能是转发和路由)节点来说，TCP/IP协议栈并不是数据转发的索必须的。因此在IA架构下引入了DPDK技术，来解决高性能的包处理能力


#### DPDK 优势
- 轮询，避免中断上下文的切换的开销，Linux NAPI就是采用这样的一种方式

- 用户态驱动,在用户态下工作，既规避了不必要的内核拷贝又避免了系统调用，一个明显的特点是用户态驱动不受限于内核现有的数据格式和定义。对mbuf头结构的重新定义，对网卡DMA操作的重新优化可以获得更好的性能。

- 亲和性与cpu core独占,DPDK工作在用户态，线程的调度仍然是依赖内核，利用线程的CPU亲和性和绑定的方式，特定任务可以被指定只在某个核上工作，可以避免不同核之间的频繁切换，CPU core之间的核心切换会导致cache miss和cache write back造成的大量性能损失。

- 降低内存的开销，网络数据包是IO密集型的工作负载，无论是CPU还是DMA，对于内存子系统(Memory/Cache)都会频繁访问，可以利用一些已知的高效方法来减少内存你的开销来提升性能，比如利用内存大页的方式来降低TLB miss的

  

#### DPDK 包含了哪几个部分？

- 核心库Core Libs,提供系统抽象，大页内存、缓存池、定时器以及无锁环等基础组件
- PMD库，提供全用户态的驱动，以便通过轮询和线程绑定来得到极高的网络吞吐，支持本地各种各样的虚拟网卡
- Classify库，支持精确匹配，最长匹配和通配符匹配，提供常用包处理的查表操作
- QoS库,提供网络服务质量相关组件，如限速和调度。

#### DPDK加速存储应用

- Intel 的SDPK是一款存储加速的开发套件，主要场景是应用于iSCSI的应用。目前iSCSI系统包括前端和后端两个部分，在前端，DPDK提供网络IO加速，加上一套用户态TCP/IP，以流水线的工作方式支撑起基于iSCSI的应用；在后端将DPDK用户态轮询驱动的方式来实践在NVME上，PMD的NVME驱动加速后端的存储访问，这是一个端到端的方案，用数据证明了卓有成效的IOPS性能提升。

